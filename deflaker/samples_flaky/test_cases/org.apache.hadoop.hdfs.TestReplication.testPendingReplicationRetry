/* This test makes sure that NameNode retries all the available blocks 
   * for under replicated blocks. 
   * 
   * It creates a file with one block and replication of 4. It corrupts 
   * two of the blocks and removes one of the replicas. Expected behavior is
   * that missing replica will be copied from one valid source.
   */
public void testPendingReplicationRetry() throws IOException {
    MiniDFSCluster cluster = null;
    int numDataNodes = 4;
    String testFile = "/replication-test-file";
    Path testPath = new Path(testFile);
    byte[] buffer = new byte[1024];
    for (int i = 0; i < buffer.length; i++) {
        buffer[i] = '1';
    }
    try {
        Configuration conf = new HdfsConfiguration();
        conf.set(DFSConfigKeys.DFS_REPLICATION_KEY, Integer.toString(numDataNodes));
        // first time format
        cluster = new MiniDFSCluster.Builder(conf).numDataNodes(numDataNodes).build();
        cluster.waitActive();
        DFSClient dfsClient = new DFSClient(new InetSocketAddress("localhost", cluster.getNameNodePort()), conf);
        OutputStream out = cluster.getFileSystem().create(testPath);
        out.write(buffer);
        out.close();
        waitForBlockReplication(testFile, dfsClient.getNamenode(), numDataNodes, -1);
        // get first block of the file.
        ExtendedBlock block = dfsClient.getNamenode().getBlockLocations(testFile, 0, Long.MAX_VALUE).get(0).getBlock();
        cluster.shutdown();
        cluster = null;
        for (int i = 0; i < 25; i++) {
            buffer[i] = '0';
        }
        int fileCount = 0;
        // Choose 3 copies of block file - delete 1 and corrupt the remaining 2
        for (int dnIndex = 0; dnIndex < 3; dnIndex++) {
            File blockFile = MiniDFSCluster.getBlockFile(dnIndex, block);
            LOG.info("Checking for file " + blockFile);
            if (blockFile != null && blockFile.exists()) {
                if (fileCount == 0) {
                    LOG.info("Deleting file " + blockFile);
                    assertTrue(blockFile.delete());
                } else {
                    // corrupt it.
                    LOG.info("Corrupting file " + blockFile);
                    long len = blockFile.length();
                    assertTrue(len > 50);
                    RandomAccessFile blockOut = new RandomAccessFile(blockFile, "rw");
                    try {
                        blockOut.seek(len / 3);
                        blockOut.write(buffer, 0, 25);
                    } finally {
                        blockOut.close();
                    }
                }
                fileCount++;
            }
        }
        assertEquals(3, fileCount);
        /* Start the MiniDFSCluster with more datanodes since once a writeBlock
       * to a datanode node fails, same block can not be written to it
       * immediately. In our case some replication attempts will fail.
       */
        LOG.info("Restarting minicluster after deleting a replica and corrupting 2 crcs");
        conf = new HdfsConfiguration();
        conf.set(DFSConfigKeys.DFS_REPLICATION_KEY, Integer.toString(numDataNodes));
        conf.set(DFSConfigKeys.DFS_NAMENODE_REPLICATION_PENDING_TIMEOUT_SEC_KEY, Integer.toString(2));
        conf.set("dfs.datanode.block.write.timeout.sec", Integer.toString(5));
        // only 3 copies exist
        conf.set(DFSConfigKeys.DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY, "0.75f");
        cluster = new MiniDFSCluster.Builder(conf).numDataNodes(numDataNodes * 2).format(false).build();
        cluster.waitActive();
        dfsClient = new DFSClient(new InetSocketAddress("localhost", cluster.getNameNodePort()), conf);
        waitForBlockReplication(testFile, dfsClient.getNamenode(), numDataNodes, -1);
    } finally {
        if (cluster != null) {
            cluster.shutdown();
        }
    }
}
