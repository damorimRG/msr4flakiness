/**
 * Like the previous test but create many files. This covers bugs where
 * the quota adjustment is incorrect but it takes many files to accrue
 * a big enough accounting error to violate the quota.
 */
@Test
public void testMultipleFilesSmallerThanOneBlock() throws Exception {
    Configuration conf = new HdfsConfiguration();
    final int BLOCK_SIZE = 6 * 1024;
    conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, BLOCK_SIZE);
    conf.setBoolean(DFSConfigKeys.DFS_WEBHDFS_ENABLED_KEY, true);
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();
    FileSystem fs = cluster.getFileSystem();
    DFSAdmin admin = new DFSAdmin(conf);
    final String nnAddr = conf.get(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY);
    final String webhdfsuri = WebHdfsFileSystem.SCHEME + "://" + nnAddr;
    System.out.println("webhdfsuri=" + webhdfsuri);
    final FileSystem webhdfs = new Path(webhdfsuri).getFileSystem(conf);
    try {
        // Test for deafult NameSpace Quota
        long nsQuota = FSImageTestUtil.getNSQuota(cluster.getNameNode().getNamesystem());
        assertTrue("Default namespace quota expected as long max. But the value is :" + nsQuota, nsQuota == Long.MAX_VALUE);
        Path dir = new Path("/test");
        boolean exceededQuota = false;
        ContentSummary c;
        // 1kb file
        // 6kb block
        // 192kb quota
        final int FILE_SIZE = 1024;
        final int QUOTA_SIZE = 32 * (int) fs.getDefaultBlockSize();
        assertEquals(6 * 1024, fs.getDefaultBlockSize());
        assertEquals(192 * 1024, QUOTA_SIZE);
        // Create the dir and set the quota. We need to enable the quota before
        // writing the files as setting the quota afterwards will over-write
        // the cached disk space used for quota verification with the actual
        // amount used as calculated by INode#spaceConsumedInTree.
        assertTrue(fs.mkdirs(dir));
        runCommand(admin, false, "-setSpaceQuota", Integer.toString(QUOTA_SIZE), dir.toString());
        // We can create at most 59 files because block allocation is
        // conservative and initially assumes a full block is used, so we
        // need to leave at least 3 * BLOCK_SIZE free space when allocating
        // the last block: (58 * 3 * 1024) (3 * 6 * 1024) = 192kb
        for (int i = 0; i < 59; i++) {
            Path file = new Path("/test/test" + i);
            DFSTestUtil.createFile(fs, file, FILE_SIZE, (short) 3, 1L);
            DFSTestUtil.waitReplication(fs, file, (short) 3);
        }
        // Should account for all 59 files (almost QUOTA_SIZE)
        c = fs.getContentSummary(dir);
        checkContentSummary(c, webhdfs.getContentSummary(dir));
        assertEquals("Invalid space consumed", 59 * FILE_SIZE * 3, c.getSpaceConsumed());
        assertEquals("Invalid space consumed", QUOTA_SIZE - (59 * FILE_SIZE * 3), 3 * (fs.getDefaultBlockSize() - FILE_SIZE));
        // Now check that trying to create another file violates the quota
        try {
            Path file = new Path("/test/test59");
            DFSTestUtil.createFile(fs, file, FILE_SIZE, (short) 3, 1L);
            DFSTestUtil.waitReplication(fs, file, (short) 3);
        } catch (QuotaExceededException e) {
            exceededQuota = true;
        }
        assertTrue("Quota not exceeded", exceededQuota);
    } finally {
        cluster.shutdown();
    }
}
