@Test
public void testFileChecksum() throws Exception {
    ((Log4JLogger) HftpFileSystem.LOG).getLogger().setLevel(Level.ALL);
    final long seed = RAN.nextLong();
    System.out.println("seed=" + seed);
    RAN.setSeed(seed);
    final Configuration conf = getTestConfiguration();
    conf.setBoolean(DFSConfigKeys.DFS_WEBHDFS_ENABLED_KEY, true);
    conf.set(DFSConfigKeys.DFS_DATANODE_HOST_NAME_KEY, "localhost");
    final MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
    final FileSystem hdfs = cluster.getFileSystem();
    final String nnAddr = conf.get(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY);
    final UserGroupInformation current = UserGroupInformation.getCurrentUser();
    final UserGroupInformation ugi = UserGroupInformation.createUserForTesting(current.getShortUserName() + "x", new String[] { "user" });
    // hftp
    final String hftpuri = "hftp://" + nnAddr;
    System.out.println("hftpuri=" + hftpuri);
    final FileSystem hftp = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {

        @Override
        public FileSystem run() throws Exception {
            return new Path(hftpuri).getFileSystem(conf);
        }
    });
    // webhdfs
    final String webhdfsuri = WebHdfsFileSystem.SCHEME + "://" + nnAddr;
    System.out.println("webhdfsuri=" + webhdfsuri);
    final FileSystem webhdfs = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {

        @Override
        public FileSystem run() throws Exception {
            return new Path(webhdfsuri).getFileSystem(conf);
        }
    });
    final Path dir = new Path("/filechecksum");
    final int block_size = 1024;
    final int buffer_size = conf.getInt("io.file.buffer.size", 4096);
    conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY, 512);
    // try different number of blocks
    for (int n = 0; n < 5; n++) {
        // generate random data
        final byte[] data = new byte[RAN.nextInt(block_size / 2 - 1) + n * block_size + 1];
        RAN.nextBytes(data);
        System.out.println("data.length=" + data.length);
        // write data to a file
        final Path foo = new Path(dir, "foo" + n);
        {
            final FSDataOutputStream out = hdfs.create(foo, false, buffer_size, (short) 2, block_size);
            out.write(data);
            out.close();
        }
        // compute checksum
        final FileChecksum hdfsfoocs = hdfs.getFileChecksum(foo);
        System.out.println("hdfsfoocs=" + hdfsfoocs);
        // hftp
        final FileChecksum hftpfoocs = hftp.getFileChecksum(foo);
        System.out.println("hftpfoocs=" + hftpfoocs);
        final Path qualified = new Path(hftpuri + dir, "foo" + n);
        final FileChecksum qfoocs = hftp.getFileChecksum(qualified);
        System.out.println("qfoocs=" + qfoocs);
        // webhdfs
        final FileChecksum webhdfsfoocs = webhdfs.getFileChecksum(foo);
        System.out.println("webhdfsfoocs=" + webhdfsfoocs);
        final Path webhdfsqualified = new Path(webhdfsuri + dir, "foo" + n);
        final FileChecksum webhdfs_qfoocs = webhdfs.getFileChecksum(webhdfsqualified);
        System.out.println("webhdfs_qfoocs=" + webhdfs_qfoocs);
        // write another file
        final Path bar = new Path(dir, "bar" + n);
        {
            final FSDataOutputStream out = hdfs.create(bar, false, buffer_size, (short) 2, block_size);
            out.write(data);
            out.close();
        }
        {
            // verify checksum
            final FileChecksum barcs = hdfs.getFileChecksum(bar);
            final int barhashcode = barcs.hashCode();
            assertEquals(hdfsfoocs.hashCode(), barhashcode);
            assertEquals(hdfsfoocs, barcs);
            // hftp
            assertEquals(hftpfoocs.hashCode(), barhashcode);
            assertEquals(hftpfoocs, barcs);
            assertEquals(qfoocs.hashCode(), barhashcode);
            assertEquals(qfoocs, barcs);
            // webhdfs
            assertEquals(webhdfsfoocs.hashCode(), barhashcode);
            assertEquals(webhdfsfoocs, barcs);
            assertEquals(webhdfs_qfoocs.hashCode(), barhashcode);
            assertEquals(webhdfs_qfoocs, barcs);
        }
        hdfs.setPermission(dir, new FsPermission((short) 0));
        {
            // test permission error on hftp
            try {
                hftp.getFileChecksum(qualified);
                fail();
            } catch (IOException ioe) {
                FileSystem.LOG.info("GOOD: getting an exception", ioe);
            }
        }
        {
            // test permission error on webhdfs
            try {
                webhdfs.getFileChecksum(webhdfsqualified);
                fail();
            } catch (IOException ioe) {
                FileSystem.LOG.info("GOOD: getting an exception", ioe);
            }
        }
        hdfs.setPermission(dir, new FsPermission((short) 0777));
    }
    cluster.shutdown();
}
