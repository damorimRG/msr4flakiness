/**
 * Test reading while writing.
 */
@Test
public void pipeline_02_03() throws Exception {
    final Configuration conf = new HdfsConfiguration();
    // enable append
    conf.setBoolean(DFSConfigKeys.DFS_SUPPORT_APPEND_KEY, true);
    conf.setLong(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY, 1);
    // create cluster
    final MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(4).build();
    try {
        // change the lease limits.
        cluster.setLeasePeriod(SOFT_LEASE_LIMIT, HARD_LEASE_LIMIT);
        // wait for the cluster
        cluster.waitActive();
        final FileSystem fs = cluster.getFileSystem();
        final Path p = new Path(DIR, "file1");
        final int half = BLOCK_SIZE / 2;
        // a. On Machine M1, Create file. Write half block of data.
        // Invoke DFSOutputStream.hflush() on the dfs file handle.
        // Do not close file yet.
        {
            final FSDataOutputStream out = fs.create(p, true, fs.getConf().getInt("io.file.buffer.size", 4096), (short) 3, BLOCK_SIZE);
            write(out, 0, half);
            // hflush
            ((DFSOutputStream) out.getWrappedStream()).hflush();
        }
        // b. On another machine M2, open file and verify that the half-block
        // of data can be read successfully.
        checkFile(p, half, conf);
        AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
        ((DistributedFileSystem) fs).dfs.leaserenewer.interruptAndJoin();
        // c. On M1, append another half block of data.  Close file on M1.
        {
            // sleep to let the lease is expired.
            Thread.sleep(2 * SOFT_LEASE_LIMIT);
            final UserGroupInformation current = UserGroupInformation.getCurrentUser();
            final UserGroupInformation ugi = UserGroupInformation.createUserForTesting(current.getShortUserName() + "x", new String[] { "supergroup" });
            final DistributedFileSystem dfs = ugi.doAs(new PrivilegedExceptionAction<DistributedFileSystem>() {

                @Override
                public DistributedFileSystem run() throws Exception {
                    return (DistributedFileSystem) FileSystem.newInstance(conf);
                }
            });
            final FSDataOutputStream out = append(dfs, p);
            write(out, 0, half);
            out.close();
        }
        // d. On M2, open file and read 1 block of data from it. Close file.
        checkFile(p, 2 * half, conf);
    } finally {
        cluster.shutdown();
    }
}
