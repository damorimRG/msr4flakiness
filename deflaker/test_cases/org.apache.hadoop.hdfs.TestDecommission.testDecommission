/**
 * Tests decommission for non federated cluster
 */
@Test
public void testDecommission() throws IOException {
    testDecommission(1, 6);
}
private void testDecommission(int numNamenodes, int numDatanodes) throws IOException {
    LOG.info("Starting test testDecommission");
    startCluster(numNamenodes, numDatanodes, conf);
    ArrayList<ArrayList<DatanodeInfo>> namenodeDecomList = new ArrayList<ArrayList<DatanodeInfo>>(numNamenodes);
    for (int i = 0; i < numNamenodes; i++) {
        namenodeDecomList.add(i, new ArrayList<DatanodeInfo>(numDatanodes));
    }
    Path file1 = new Path("testDecommission.dat");
    for (int iteration = 0; iteration < numDatanodes - 1; iteration++) {
        int replicas = numDatanodes - iteration - 1;
        // Start decommissioning one namenode at a time
        for (int i = 0; i < numNamenodes; i++) {
            ArrayList<DatanodeInfo> decommissionedNodes = namenodeDecomList.get(i);
            FileSystem fileSys = cluster.getFileSystem(i);
            writeFile(fileSys, file1, replicas);
            // Decommission one node. Verify that node is decommissioned.
            DatanodeInfo decomNode = decommissionNode(i, decommissionedNodes, AdminStates.DECOMMISSIONED);
            decommissionedNodes.add(decomNode);
            // Ensure decommissioned datanode is not automatically shutdown
            DFSClient client = getDfsClient(cluster.getNameNode(i), conf);
            assertEquals("All datanodes must be alive", numDatanodes, client.datanodeReport(DatanodeReportType.LIVE).length);
            assertNull(checkFile(fileSys, file1, replicas, decomNode.getName(), numDatanodes));
            cleanupFile(fileSys, file1);
        }
    }
    // Restart the cluster and ensure recommissioned datanodes
    // are allowed to register with the namenode
    cluster.shutdown();
    startCluster(numNamenodes, numDatanodes, conf);
    cluster.shutdown();
}
